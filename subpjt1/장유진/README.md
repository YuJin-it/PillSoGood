# 아이디어 기획

## 프로젝트 개요

**프로젝트 명**: 필쏘굿 (Pill So Good)

**팀원 정보 및 업무 분담**

- 프로젝트 기간 : 24.08.26 ~ 진행 중
  | 이름 | 역할 |
  | ------ | -------------- |
  | 최용훈 | 팀 리더 |
  | 정경원 | Back-End 팀장 |
  | 한지훈 | Back-End 팀원 |
  | 이용성 | Front-End 팀장 |
  | 장유진 | Front-End 팀원 |
  | 박선민 | Front-End 팀원 |

**프로젝트 목적**:
약물 오남용은 심각한 건강 문제로 이어질 수 있으며, 특히 장기적으로 약물을 복용해야 하거나 특정 약물 성분에 민감한 사람들에게는 더욱 주의가 필요합니다. 'OOO' 서비스는 이러한 위험을 최소화하고 사용자가 안전하게 약을 복용할 수 있도록 지원하는 것을 목표로 합니다. 이 서비스는 사용자가 복용 중인 약물의 조합과 개인적인 건강 상태를 바탕으로, 약물 상호작용 및 복용 가능 여부를 안내하여 오남용을 예방하고, 건강을 지킬 수 있도록 돕습니다.

### 서비스 타겟

- 장기 복약이 필요한 환자
- 특정 성분에 민감한 사람들
- 임산부
- 고령자 및 소아
- 스테로이드 등 오남용 위험이 있는 약물을 복용하는 사람들

### 페르소나 1: 김민수 (45세, 남성, 만성질환자)

**배경** : 김민수 씨는 고혈압과 당뇨병을 앓고 있어, 여러 약물을 장기간 복용해야 합니다. 그는 일상생활이 바쁘다 보니 종종 약 복용을 잊거나, 병용 약물의 부작용에 대해 걱정이 많습니다.
**니즈** :

- 복용 중인 약물의 안전성 검토
- 복약 시간을 잊지 않도록 알림 기능
- 약물 상호작용 위험에 대한 안내
  **목표** :
- 약물 복용을 안전하게 관리하고, 복약 시간을 잘 지켜 건강 상태를 개선하는 것.

### 페르소나 2: 이지영 (32세, 여성, 임산부)

**배경**:
이지영 씨는 임신 6개월 차로, 임신 중에 복용할 수 있는 약물에 대해 많은 관심과 걱정을 가지고 있습니다. 특히, 평소 앓고 있는 편두통 약이 태아에게 미칠 영향이 걱정됩니다.
**니즈**:

- 임신 중 안전한 약물 복용 안내
- 복약 정보에 대한 쉽게 접근할 수 있는 정보 제공
- 복용 약물과 임신 상태를 기반으로 한 안전성 검토
  **목표**:
- 임신 중에도 안전하게 약물을 복용하고, 태아의 건강을 지키는 것.

### 페르소나 3: 박성준 (70세, 남성, 고령자)

**배경**:
박성준 씨는 고령자로, 복용해야 하는 약이 많습니다. 하지만 약물의 이름을 헷갈리거나, 복약 시간과 용량을 잊어버리기 쉽습니다. 그는 간단한 사용법으로 모든 복약 정보를 관리하고 싶어 합니다.
**니즈**:

- 약물 이름과 복용 방법을 쉽게 관리할 수 있는 시스템
- 복약 알림 기능
- 약물 상호작용에 대한 간단한 안내
  **목표**:
- 혼동 없이 약물을 정확하게 복용하고, 약물 상호작용으로 인한 문제를 피하는 것.

### 페르소나 4: 정은영 (28세, 여성, 알러지 환자)

**배경**:
정은영 씨는 특정 성분에 심각한 알러지가 있어, 약물 복용 시 항상 주의를 기울입니다. 그녀는 자신이 복용할 수 있는 약물인지 여부를 빠르고 정확하게 확인하고 싶어 합니다.
**니즈**:

- 특정 성분에 대한 알러지 위험성 안내
- 약물 등록 후, 알러지 성분 포함 여부 자동 확인
- 약국으로 빠르게 문의할 수 있는 기능
  **목표** :
- 알러지 위험을 피하고, 안전하게 약을 복용하는 것.

### 메인 기능

- 회원가입 및 소셜 로그인(카카오)
- 로그인 및 사용자 정보 관리
- 기존 약물 등록
- 약물 투약 계획 등록
- 복약 기록 관리
- 약물 조합 검색 및 결과 출력
- 복약 알림 기능
- 영양제 오남용 예방 기능

### 메인 기능 설명

1. 회원가입 및 소셜 로그인
   기능 설명:
   사용자는 카카오톡 소셜 로그인을 통해 간편하게 회원가입을 할 수 있습니다. 소셜로그인으로 이름, 나이, 성별 정보를 받아옵니다.

2. 로그인 및 사용자 정보 관리
   기능 설명:
   로그인 후, 사용자는 알러지 여부, 임신 여부, 복약 정보 등 추가적인 개인 건강 정보를 별도로 등록할 수 있습니다. 이는 서비스에서 맞춤형 정보를 제공하는 데 사용됩니다.

3. 기존 약물 등록
   기능 설명:
   사용자는 복용 중인 약물을 직접 등록할 수 있습니다. 약물 정보를 직접 입력하거나, API를 통해 기존 복약 정보를 불러올 수 있습니다.

4. 약물 투약 계획 등록
   기능 설명:
   사용자는 특정 약물의 복약 계획을 등록할 수 있습니다. 이는 약물의 복용 시간과 빈도에 따라 설정되며, 이후 복약 알림과 연동됩니다.

5. 복약 기록 관리
   기능 설명:
   사용자가 약을 복용한 기록을 캘린더 형식으로 관리할 수 있습니다. 복약 알림을 통해 기록을 쉽게 남길 수 있으며, 복약 기록을 시각적으로 확인할 수 있습니다.

6. 약물 조합 검색 및 결과 출력
   기능 설명:
   사용자는 복용 중인 약물의 조합을 검색하고, 연령, 임신부 여부 등의 조건에 따라 결과를 확인할 수 있습니다. 결과는 약물 간의 상호작용에 따라 주의가 필요한 사항들을 출력하며, 필요한 경우 의사와 상담할 것을 권장합니다.

예시:
주의 2건
1번약, 2번약 복통 유발 가능성
3번약, 5번약 유산산성증 유발 가능성
⇒ 의사 확인 필요

기대 효과:
약물 간 상호작용으로 인한 위험을 미리 인지하고 예방할 수 있습니다.

7. 복약 알림 기능
   기능 설명:
   사용자가 설정한 시간에 푸쉬 알림을 통해 복약을 안내합니다. 알림창에서 바로 복약 기록을 처리할 수 있으며, 필요시 알림을 미룰 수도 있습니다.

8. 영양제 오남용 예방 기능(부가기능)
   기능 설명:
   사용자가 여러 종류의 영양제를 복용할 경우, 성분별 하루 권장 섭취량을 초과하지 않도록 경고합니다. 영양제 성분이 겹칠 때 하루 권장량을 초과하는지 여부를 확인하여, 초과 시 주의를 안내합니다.

### 예상되는 필요 기술 스택

- **백엔드**
  - Apache Spark, Apache Kafka, MySQL, Hadoop HDFS, Redis, Elastic Search
- **프론트엔드**
  - React, Redux, Emotion

---

# 개인학습 내용

## 맵 리듀스

- 대량의 데이터를 처리하고 분석하기 위해 개발된 프로그래밍 모델이자 프레임워크입니다. 이 모델은 Google에서 처음 제안되었으며, 대규모 데이터 세트를 분산 환경에서 효과적으로 처리하기 위해 설계되었습니다.

1. 맵(Map) 단계
   우리가 큰 문제를 여러 사람에게 나눠서 해결하는 상황을 생각해보세요. 예를 들어, 친구들과 함께 많은 양의 과일을 분류한다고 해봅시다. 각 친구가 자기 앞에 있는 과일들을 사과, 오렌지, 바나나 등으로 분류하는 작업을 맡게 됩니다. 이 과정이 바로 맵(Map) 단계입니다. 각각의 친구가 받은 과일을 특정 카테고리(키)로 분류하는 것이죠.

2. 셔플링(Shuffling) 단계
   맵 단계가 끝나면, 같은 종류의 과일을 가진 친구들을 한 그룹으로 모아야겠죠? 사과를 분류한 친구들은 사과만 모아서 한곳에, 오렌지는 오렌지만 모아서 다른 곳에 모이는 과정이 필요합니다. 이 과정이 바로 셔플링(Shuffling) 단계입니다. 셔플링은 같은 키를 가진 데이터를 모아서 같은 리듀서(Reducer)로 보내는 과정입니다.

3. 리듀스(Reduce) 단계
   이제 각 과일 그룹마다 총 몇 개의 과일이 있는지 세어봅시다. 사과 그룹에서는 사과의 총 개수를, 오렌지 그룹에서는 오렌지의 총 개수를 세는 작업이 필요하죠. 이 과정이 바로 리듀스(Reduce) 단계입니다. 리듀스 단계에서는 셔플링을 통해 모인 데이터를 처리하여 최종 결과를 도출합니다.

실제 예시: 단어 빈도 계산
단어 빈도를 계산하는 예시를 들어볼게요. 많은 양의 텍스트 파일에서 각 단어가 몇 번 등장하는지 세고 싶다고 합시다.

맵(Map) 단계: 각 텍스트 파일을 읽고, 등장하는 모든 단어를 '단어: 1' 형태로 기록합니다. 예를 들어, "사과 바나나 사과"라는 텍스트가 있다면, 맵 단계에서는 '사과: 1', '바나나: 1', '사과: 1'과 같은 중간 결과가 생성됩니다.

셔플링(Shuffling) 단계: 맵 단계에서 생성된 중간 결과들을 같은 단어끼리 모아줍니다. '사과: 1', '사과: 1'은 같이 모이고, '바나나: 1'은 따로 모입니다. 즉, 같은 단어를 가진 데이터가 한데 모이는 과정입니다.

리듀스(Reduce) 단계: 이제 같은 단어끼리 모인 그룹에서 해당 단어가 몇 번 등장했는지 합산합니다. 예를 들어, '사과: 1', '사과: 1'이 모였다면, 최종 결과는 '사과: 2'가 됩니다. 이렇게 모든 단어에 대해 빈도를 계산할 수 있습니다.

## 하둡과 스파크의 차이

### 1. **데이터 처리 방식**

- **하둡**: 하둡의 핵심 구성 요소인 맵리듀스(MapReduce)는 **배치 처리(batch processing)** 방식으로 데이터를 처리함. 맵리듀스는 데이터를 여러 단계로 나눠 순차적으로 처리하며, 각 단계마다 데이터를 디스크에 저장했다가 다음 단계로 넘기는 방식임. 이 때문에 **디스크 I/O(입출력) 오버헤드**가 발생해 속도가 느릴 수 있음.

- **스파크**: 스파크는 **메모리 기반의 데이터 처리**를 지원함. 스파크의 가장 큰 장점은 데이터를 **메모리에 유지**하면서 연산을 수행한다는 점임. 이를 통해 디스크에 데이터를 반복해서 쓰고 읽는 **오버헤드를 줄여** 훨씬 **빠른 처리가 가능**함. 특히, 반복적인 작업이나 실시간 스트리밍 작업에서 뛰어난 성능을 발휘함.

### 2. **속도 및 성능**

- **하둡**: 하둡은 데이터 처리 속도가 **상대적으로 느림**. 맵리듀스의 구조상 각 단계에서 디스크에 데이터를 저장해야 하므로, 대용량 데이터에 대해 병렬 처리의 이점은 있지만, **I/O 비용이 큼**.

- **스파크**: 스파크는 하둡보다 **최대 100배 빠른 성능**을 자랑함. 스파크는 데이터 처리를 **메모리에서 수행**하기 때문에, 반복 작업(예: 기계 학습 모델 훈련)에서 특히 **속도가 빠름**. 스파크는 또한 **DAG(Directed Acyclic Graph) 엔진**을 사용해 작업의 최적 경로를 자동으로 계산하고 병렬 처리를 극대화함.

### 3. **유연성**

- **하둡**: 하둡은 주로 **배치 작업에 최적화**되어 있으며, **실시간 데이터 처리를 위한 기능은 제한적**임. 스트리밍 데이터를 처리하기 위해서는 별도의 프레임워크(예: Apache Storm)와 결합하여 사용해야 함.

- **스파크**: 스파크는 배치 처리뿐만 아니라 **실시간 스트리밍, 인터랙티브 쿼리, 그래프 처리, 기계 학습**까지 하나의 통합된 프레임워크에서 모두 처리할 수 있음. **스파크 스트리밍(Spark Streaming)**을 통해 실시간 데이터 스트림을 쉽게 처리할 수 있어 다양한 데이터 처리 요구를 한 번에 해결할 수 있음.

### 4. **사용의 용이성**

- **하둡**: 하둡은 맵리듀스의 **복잡한 프로그래밍 모델**을 사용함. 개발자가 맵리듀스 작업을 작성하려면, 데이터 흐름을 잘 이해하고, 각 단계에서 데이터를 어떻게 처리할지 명시해야 함.

- **스파크**: 스파크는 **RDD(Resilient Distributed Datasets)**라는 **추상화된 데이터 구조**를 제공해, 개발자가 더 **직관적이고 간단하게** 데이터를 처리할 수 있게 해줌. 또한, 스파크는 SQL, Python, Scala, Java와 같은 **다양한 언어를 지원**하여 더 넓은 개발자 커뮤니티에 접근성을 제공함.

### 5. **왜 스파크가 더 트렌디한가?**

- **속도**: 스파크의 **메모리 기반 처리** 덕분에 데이터 처리 속도가 훨씬 **빠름**. 특히, 기계 학습이나 반복 연산이 필요한 빅데이터 분석에서 스파크의 이점이 더욱 **두드러짐**.

- **다양한 처리 기능**: 스파크는 배치 처리 외에도 **실시간 스트리밍, 기계 학습, 그래프 처리** 등 다양한 기능을 통합적으로 제공하기 때문에, 여러 요구 사항을 한 번에 해결할 수 있음. 이것이 스파크가 **다목적 빅데이터 처리 플랫폼**으로 인기를 끌고 있는 이유 중 하나임.

- **사용 편의성**: 스파크의 **프로그래밍 모델**은 하둡보다 **간단하고 직관적**임. 이는 더 많은 개발자들이 스파크를 쉽게 학습하고 사용할 수 있게 해주며, 결과적으로 스파크의 **채택이 더 빠르게** 이루어지고 있음.

### 결론

스파크는 하둡의 단점을 보완하면서 더 **빠르고 유연한 빅데이터 처리**를 가능하게 함. 특히, 실시간 데이터 분석과 기계 학습 작업의 증가로 인해, 스파크의 **메모리 기반 처리 능력**과 **통합적인 데이터 처리 기능**이 더욱 주목받고 있음. 이러한 이유로 스파크가 현재 **빅데이터 처리의 트렌드**로 자리 잡게 됨.

## 빅데이터란?

### 1. **빅데이터의 정의**

- **빅데이터**: 빅데이터는 **대규모, 복잡성, 빠른 생성 속도를 가진 데이터**를 의미함. 기존의 데이터베이스 관리 도구나 전통적인 데이터 처리 방법으로는 다루기 어려운 데이터임. **데이터의 양**(Volume), **생성 속도**(Velocity), **다양성**(Variety), **진실성**(Veracity), **가치**(Value)라는 **5V**로 설명됨.

- **5V**:
  - **Volume(양)**: 데이터의 양이 방대함. 페타바이트(PB) 또는 엑사바이트(EB) 단위로 측정될 수 있음.
  - **Velocity(속도)**: 데이터 생성 및 처리 속도가 매우 빠름. 실시간 또는 거의 실시간으로 데이터가 생성되고 분석됨.
  - **Variety(다양성)**: 데이터의 형식이 다양함. 정형 데이터, 비정형 데이터, 반정형 데이터 등을 포함함.
  - **Veracity(진실성)**: 데이터의 품질과 신뢰성. 데이터가 얼마나 정확하고 신뢰할 수 있는지를 나타냄.
  - **Value(가치)**: 데이터를 통해 얻을 수 있는 인사이트와 정보의 가치.

### 2. **빅데이터의 활용**

- **산업별 활용**: 빅데이터는 다양한 산업에서 혁신을 이끌고 있음. 데이터 분석을 통해 고객 행동 예측, 개인화 서비스 제공, 효율적인 운영 등이 가능함.
  - **금융**: 신용 리스크 평가, 사기 탐지, 맞춤형 금융 상품 제공.
  - **의료**: 환자 데이터 분석을 통한 맞춤형 치료, 질병 예측, 건강 관리.
  - **소매업**: 고객 행동 분석을 통한 마케팅 전략 수립, 재고 관리 최적화.
  - **교통**: 실시간 교통 흐름 분석, 최적 경로 제안, 차량 유지 보수 예측.

### 3. **빅데이터 처리 기술**

- **하둡(Hadoop)**: 하둡은 분산 저장과 분산 처리를 지원하는 빅데이터 플랫폼임. 대규모 데이터를 여러 노드에 분산 저장하고, 이를 병렬로 처리할 수 있음. 데이터의 내결함성과 확장성이 높음.
- **스파크(Spark)**: 스파크는 메모리 기반의 분산 처리 플랫폼으로, 하둡보다 훨씬 빠른 속도로 데이터를 처리할 수 있음. 실시간 데이터 처리, 기계 학습, 스트리밍 처리 등 다양한 기능을 제공함.

- **NoSQL 데이터베이스**: 전통적인 관계형 데이터베이스와 달리, NoSQL 데이터베이스는 구조화되지 않거나 반구조화된 데이터를 효율적으로 저장하고 검색할 수 있음. 예: MongoDB, Cassandra.

### 4. **빅데이터의 도전 과제**

- **데이터 관리**: 방대한 양의 데이터를 어떻게 저장하고 관리할 것인가가 큰 도전임. 저장 공간, 데이터 중복 제거, 데이터 보안 등 많은 문제가 존재함.

- **데이터 분석**: 빅데이터의 양과 복잡성 때문에, 데이터를 어떻게 분석하고 유의미한 인사이트를 도출할 것인지가 과제임. 고급 분석 기술과 도구가 필요함.

- **데이터 프라이버시**: 데이터의 양이 많아질수록 개인정보 보호와 관련된 문제가 심각해짐. 데이터를 분석하는 과정에서 개인의 민감한 정보가 노출될 위험이 있음.

### 5. **빅데이터의 미래**

- **기술 발전**: 클라우드 컴퓨팅, 기계 학습, 인공지능(AI)과의 결합으로 빅데이터 처리와 분석 기술이 더욱 발전할 것임. 데이터에서 더 깊은 인사이트를 도출하고, 실시간 의사결정이 가능해질 것임.

- **확장된 활용**: 빅데이터는 점점 더 많은 분야에서 핵심적인 역할을 하게 될 것임. 스마트 시티, 자율 주행, 개인화된 의료 등 다양한 응용 분야가 계속해서 확장될 것임.

### 결론

**빅데이터**는 현대 사회에서 **핵심 자원**으로 자리 잡고 있음. 방대한 데이터를 효율적으로 수집, 저장, 분석함으로써, 기업과 사회는 중요한 인사이트를 얻고 경쟁력을 강화할 수 있음. **빅데이터 기술의 발전**은 앞으로도 다양한 분야에서 **혁신을 주도**할 것으로 기대됨.

## 분산처리와 병렬처리

### 1. **데이터의 분산 처리**

- **분산 처리**: 데이터의 분산 처리는 **대규모 데이터를 여러 대의 컴퓨터(노드)로 나누어 처리**하는 방식임. 각 노드가 병렬로 작업을 수행하며, 전체 작업의 일부분을 맡아 처리함. 이렇게 함으로써 데이터 처리 시간을 단축할 수 있고, 하나의 노드가 고장 나더라도 다른 노드가 작업을 이어받아 처리할 수 있어 **시스템의 안정성**이 높아짐.

- **장점**:
  - **확장성**: 데이터의 양이 증가할 때, 더 많은 노드를 추가함으로써 성능을 향상시킬 수 있음.
  - **내결함성**: 한 노드의 장애가 전체 시스템의 중단으로 이어지지 않음.
- **단점**:
  - **복잡성**: 데이터를 여러 노드에 분산시키고 결과를 통합하는 과정이 복잡해질 수 있음.
  - **네트워크 오버헤드**: 노드 간의 데이터 이동이나 통신이 빈번할 경우, 네트워크 오버헤드가 발생할 수 있음.

### 2. **데이터의 병렬 처리**

- **병렬 처리**: 병렬 처리는 **하나의 작업을 여러 개의 작은 작업으로 나누어 동시에 처리하는 방식**임. 이를 통해 작업을 훨씬 더 빠르게 완료할 수 있음. 병렬 처리는 데이터의 크기뿐만 아니라 작업의 복잡성에도 영향을 받으며, 대규모 연산을 효율적으로 처리할 수 있음.

- **장점**:
  - **속도**: 여러 작업을 동시에 수행함으로써 처리 시간을 대폭 단축할 수 있음.
  - **효율성**: CPU와 같은 하드웨어 자원을 최대한 활용할 수 있음.
- **단점**:
  - **동기화 문제**: 여러 작업이 동시에 수행되기 때문에, 결과를 통합할 때 동기화 문제가 발생할 수 있음.
  - **복잡성**: 작업을 병렬화하는 과정에서 데이터 의존성이나 자원 경합과 같은 복잡한 문제가 발생할 수 있음.

### 3. **분산 처리와 병렬 처리의 결합**

- **하둡**과 **스파크**와 같은 빅데이터 프레임워크는 **분산 처리와 병렬 처리**를 결합하여 대규모 데이터 세트를 처리함.
  - **하둡**: 분산 처리에 중점을 두어, 데이터를 여러 노드에 분산시키고 병렬로 작업을 수행하지만, 각 단계에서 데이터를 디스크에 저장함.
  - **스파크**: 분산 처리와 병렬 처리를 결합해, 데이터를 메모리에 유지하면서 연산을 수행하여 훨씬 빠른 처리 속도를 제공함.

### 4. **왜 분산 처리와 병렬 처리가 중요한가?**

- **빅데이터 시대**: 데이터의 양이 기하급수적으로 증가하면서, 단일 시스템으로는 처리하기 어려운 상황이 됨. 분산 처리와 병렬 처리를 통해 대규모 데이터를 효율적으로 처리하고, 실시간 분석, 기계 학습, 스트리밍 처리와 같은 복잡한 작업을 수행할 수 있음.
- **성능 최적화**: 이 두 가지 처리는 함께 사용될 때 가장 큰 효과를 발휘함. 데이터를 여러 노드에 분산시키고, 각 노드에서 병렬로 작업을 수행함으로써 전체 시스템의 처리 능력을 극대화할 수 있음.

### 결론

**분산 처리**와 **병렬 처리**는 대규모 데이터 처리의 핵심 기술임. 이 두 가지 방법을 통해 데이터를 효율적으로 관리하고, 더 빠르고 안정적인 처리 성능을 제공할 수 있음. **빅데이터 환경에서의 성공적인 데이터 처리**는 이 두 기술의 적절한 활용에 달려있음.
